{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just to get some intution to eager execution which is a recent update in tensorflow.\n",
    "Here I used a CIFAR dataset which can be downloaded from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all the packages needed\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tce\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10(filename):                              #used to extract dataset\n",
    "\n",
    "  with open(filename, 'rb') as f:\n",
    "    if sys.version_info[0] < 3:\n",
    "      dict = pickle.load(f)\n",
    "    else:\n",
    "      dict = pickle.load(f, encoding='latin1')\n",
    "    x = dict['data']\n",
    "    y = dict['labels']\n",
    "    x = x.astype(float)\n",
    "    y = np.array(y)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():       \n",
    " #used to extract the data. \n",
    "\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for i in range(1, 6):\n",
    "    filename = 'G:\\\\My_ml_work\\\\Basic_softmax\\\\cifar-10-python\\\\cifar-10-batches-py\\\\data_batch_' + str(i)\n",
    "    X, Y = load_CIFAR10(filename)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)\n",
    " \n",
    "\n",
    "  x_train = np.concatenate(xs)\n",
    "  y_train = np.concatenate(ys)\n",
    "  del xs, ys\n",
    "  x_test, y_test = load_CIFAR10_batch('G:\\\\My_ml_work\\\\Basic_softmax\\\\cifar-10-python\\\\cifar-10-batches-py\\\\test_batch')\n",
    "\n",
    "  classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
    "    'ship', 'truck']\n",
    "\n",
    "  # Normalize Data\n",
    "  mean_image = np.mean(x_train, axis=0)\n",
    "  x_train -= mean_image\n",
    "  x_test -= mean_image\n",
    "\n",
    "  data_dict = {\n",
    "    'images_train': x_train,\n",
    "    'labels_train': y_train,\n",
    "    'images_test': x_test,\n",
    "    'labels_test': y_test,\n",
    "    'classes': classes\n",
    "  }\n",
    "  return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I defined a simple softmax classifier.So,we can't expect higher accuracy from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation=\"linear\",input_shape = (3072,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined two functions which are used to calculate loss and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model,x,y):\n",
    "    y_ = model(x)\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_,labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)  #here I used an adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 4000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tce.metrics.Mean()\n",
    "    epoch_accuracy = tce.metrics.Accuracy()\n",
    "    indices = np.random.choice(data_sets['images_train'].shape[0], batch_size)\n",
    "    images_batch = data_sets['images_train'][indices]\n",
    "    labels_batch = data_sets['labels_train'][indices]\n",
    "    #all the above steps are used to create batches\n",
    "    grads = grad(model, images_batch, labels_batch)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss(model, images_batch, labels_batch))  # add current batch loss\n",
    "    # compare predicted label to actual label\n",
    "    epoch_accuracy(tf.argmax(model(images_batch), axis=1, output_type=tf.int32), labels_batch)\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_accuracy(tf.argmax(model(data_sets['images_test']), axis=1, output_type=tf.int32), data_sets['labels_test'])\n",
    "train_loss_results.append(epoch_loss_avg.result())\n",
    "print(format(epoch_accuracy.result())) #this is to see the accuracy on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the test accuracy will not be greater than 30%.You can clearly see that I did not create any graph.I just wrote it like a python code.This is the beauty of eager execution.This is just a basic model.We can improve the perfomance of it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
